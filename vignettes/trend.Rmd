---
title: "Assessing the effects of long-term trends"
author: "Robert W Schlegel"
date: "`r Sys.Date()`"
description: "This vignette investigates the effects of long-term trends on the MHWs detected in a time series."
# output: word_document
output: rmarkdown::html_vignette
vignette: >
 %\VignetteIndexEntry{Assessing the effects of long-term trends}
 %\VignetteEngine{knitr::rmarkdown}
 %\VignetteEncoding{UTF-8}
bibliography: bibliography.bib
---

## Overview

The following text has presently just been copy pasted from the time series duration vignette and serves as a place holder for the workflow that will be used for this vignette. It is not actually meant to be read at the moment...


## Real trend vs. no trend

```{r r-init}
library(tidyverse)
library(broom)
library(heatwaveR)
library(lubridate) # This is intentionally activated after data.table
library(fasttime)
library(ggpubr)
library(boot)
library(FNN)
library(mgcv)
library(doMC); doMC::registerDoMC(cores = 3)
```

The WMO recommends that the period used to create a climatology be 30 years in length, starting on the first year of a decade (e.g. 1981), however; because we are going to be running these analyses on time series of many different lengths, it will be better to use all of the years present in each as the climatology period. For example, if a time series spans 1989 -- 2014, that will be the period used for calculating the climatologies. Likewise should the time series only span the years 2006 -- 2014.

```{r prep-funcs}
# Remove the trend from a time series
detrend <- function(df){
  resids <- broom::augment(lm(temp ~ t, df))
  res <- df %>% 
    mutate(temp = temp - resids$.fitted)
  return(res)
}
# ggplot(sst_ALL_detrend, aes(x = t, y = temp)) +
#   geom_point() +
#   geom_smooth(method = "lm") +
#   facet_wrap(~site, nrow = 3)

# Calculate one specific clim period
ts2clm_sub <- function(year_index, df){
  res <- ts2clm(df, climatologyPeriod = c(paste0(year_index,"-01-01"), "2014-12-31")) %>% 
    filter(lubridate::year(t) >= year_index) %>% 
    mutate(year_index = year_index)
  return(res)
}

# Calculate the full range of clims in a time series
ts2clm_ALL <- function(df){
  seq_year <- seq(min(lubridate::year(df$t)), 
                  max(lubridate::year(df$t))-2)
  res <- plyr::ldply(seq_year, .fun = ts2clm_sub, .parallel = T, df = df)
  return(res)
}

# Calculate decadal trends
decadal_trend <- function(df) {
  df2 <- df %>% 
    ungroup() %>%
    mutate(date = floor_date(t, "month")) %>% 
    group_by(date) %>% 
    summarise(temp = mean(temp,na.rm = T)) %>% 
    mutate(year = year(date),
           num = seq(1, n()))
    dt <- round(as.numeric(coef(gls(
      temp ~ num, correlation = corARMA(form = ~ 1 | year, p = 2),
      method = "REML", data = df2, na.action = na.exclude))[2] * 120), 3)
  return(dt)
}
```

```{r shorten}
# First put all of the data together and create a site column
sst_ALL <- rbind(sst_Med, sst_NW_Atl, sst_WA) %>% 
  mutate(site = rep(c("Med", "NW_Atl", "WA"), each = 12053))

# Then create a de-trended version
sst_ALL_detrend <- sst_ALL %>% 
  group_by(site) %>% 
  do(detrend(.)) %>% 
  ungroup() %>% 
  as.tibble(.)

# Then calculate all of the clims
## With trend left in
sst_ALL_clim <- sst_ALL %>% 
  nest(-site) %>% 
  mutate(clim = map(data, ts2clm_ALL)) %>% 
  select(-data) %>% 
  unnest()
## With de-trended data
sst_ALL_detrend_clim <- sst_ALL_detrend %>% 
  nest(-site) %>% 
  mutate(clim = map(data, ts2clm_ALL)) %>% 
  select(-data) %>% 
  unnest()
## Combine for ease later
sst_ALL_both_clim <- rbind(sst_ALL_clim, sst_ALL_detrend_clim) %>% 
  mutate(trend = rep(c("normal", "detrended"), each = nrow(sst_ALL_clim)))

# Calculate the different decadal trends
# See Schlegel and Smit 2016 for GLS model explanation/validation
sst_ALL_DT <- sst_ALL_clim %>% 
  # group_by(site) %>% 
  nest(-site) %>% 
  mutate(DT = map(data, decadal_trend)) %>% 
  select(-data) %>% 
  unnest() #%>% 
  # rename(decades = decades2)
```
```{r shorten-table}
# Quick peak at the decadal trends
knitr::kable(sst_ALL_DT, col.names = c("site", "trend (°C/dec)"), align = "c", 
             caption = "Table showing the decadal trends detected for the three default sites.", 
             digits = 3)
```

We see in the table above that the three default time series currently being used all have decadal trends much higher than the global average of ~0.1°C.

```{r compare-funcs}
# A clomp of functions used below
# Written out here for tidiness/convenience

# Calculate only events
detect_event_event <- function(df, y = temp){
  ts_y <- eval(substitute(y), df)
  df$temp <- ts_y
  res <- detect_event(df)$event
  return(res)
  }

# Run an ANOVA on each metric of the combined event results and get the p-value
event_aov_p <- function(df){
  aov_models <- df[ , -grep("year_index", names(df))] %>%
    map(~ aov(.x ~ df$year_index)) %>% 
    map_dfr(~ broom::tidy(.), .id = 'metric') %>%
    mutate(p.value = round(p.value, 4)) %>%
    filter(term != "Residuals") %>%
    select(metric, p.value)
  return(aov_models)
  }

# Run an ANOVA on each metric and then a Tukey test
event_aov_tukey <- function(df){
  aov_tukey <- df[ , -grep("year_index", names(df))] %>%
    map(~ TukeyHSD(aov(.x ~ df$year_index))) %>% 
    map_dfr(~ broom::tidy(.), .id = 'metric') %>%
    mutate(p.value = round(adj.p.value, 4)) %>%
    # filter(term != "Residuals") %>%
    select(metric, comparison, adj.p.value) %>% 
    # filter(adj.p.value <= 0.05) %>% 
    arrange(metric, adj.p.value)
  return(aov_tukey)
  }

# Calculate CIs using a bootstrapping technique to deal with the non-normal small sample sizes

# df <- sst_ALL_both_event %>%
#   filter(lubridate::year(date_peak) >= 2012,
#          site == "WA",
#          trend == "detrended") %>%
#   select(year_index, duration, intensity_mean, intensity_max, intensity_cumulative) #%>%
  # select(site, trend, year_index, duration, intensity_mean, intensity_max, intensity_cumulative) #%>%   
  # nest(-site, -trend)

Bmean <- function(data, indices) {
  d <- data[indices] # allows boot to select sample 
    return(mean(d))
} 

event_aov_CI <- function(df){
  df_conf <- gather(df, key = "metric", value = "value", -year_index) %>% 
    group_by(year_index, metric) %>% 
    # ggplot(aes(x = value)) +
    # geom_histogram(aes(fill = metric)) +
    # facet_wrap(~metric, scales = "free_x")
    summarise(lower = boot.ci(boot(data=value, statistic=Bmean, R=1000), type = "basic")$basic[4],
              mid = mean(value),
              upper = boot.ci(boot(data=value, statistic=Bmean, R=1000), type = "basic")$basic[5],
              n = n()) %>% 
    mutate_if(is.numeric, round, 4)
  return(df_conf)
  }

# A particular summary output
event_output <- function(df){
  res <- df %>%
    group_by(year_index) %>% 
    # select(-event_no) %>% 
    summarise_all(c("mean", "sd"))
  return(res)
}

# Quick wrapper for getting results for ANOVA on clims
clim_aov <- function(df){
  res <- df %>% 
    select(-t, - temp, -doy) %>% 
    mutate(year_index = as.factor(year_index)) %>% 
    unique() %>% 
    group_by(site, trend) %>% 
    nest() %>% 
    mutate(res = map(data, event_aov_p)) %>% 
    select(-data) %>% 
    unnest()
  return(res)
}

# Quick wrapper for getting results for Tukey on clims
clim_tukey <- function(df){
  res <- df %>% 
    select(-t, - temp, -doy) %>% 
    mutate(year_index = as.factor(year_index)) %>% 
    unique() %>% 
    group_by(site, trend) %>% 
    nest() %>% 
    mutate(res = map(data, event_aov_tukey)) %>% 
    select(-data) %>% 
    unnest()
  return(res)
}
```


### Climatology statistics

#### ANOVA _p_-values

Given that there are perceptible differences in the mean seasonal signal values between the decades of data used, let's see if an ANOVA determines these differences to be significant.

```{r shorten-clim-aov, fig.cap="Heatmap showing the ANOVA results for the comparisons of the climatologies for the many different time periods for the default time series."}
sst_ALL_both_clim_aov <- clim_aov(sst_ALL_both_clim)

ggplot(sst_ALL_both_clim_aov, aes(x = site, y = metric)) +
  geom_tile(aes(fill = p.value)) +
  geom_text(aes(label = round(p.value, 2))) +
  scale_fill_gradient2(midpoint = 0.1) +
  facet_wrap(~trend)
```

We may see in the figure above that the climatologies do not differ appreciably at any length for the `Med`. The climatologies do however differ significantly for both the `NW_Atl` and the `WA` time series. Interestingly, when the long-term trend is removed (simple linear model flattening), the 90th percentile thresholds do not differ significantly at any length within the `NW_Atl` time series. It is worth pointing out that the `Med` time series has the lowest decadal warming trend of the three time series, that coupled with the decrease in significance for the difference in thresholds in the `NW_Atl` seems to imply that the decadal trend may play a role in determining the difference in the time series. Though the fact that the `WA` time series, by far the most variable of the three, always produces significant differences leads me to think that the variance of a time series may be able to win out over the long-term trend. This interaction will need to be quantified.


#### Post-hoc Tukey test

Before getting to that step we need to run a post-hoc Tukey test to see where the significant differences when comparing the different time series lengths begins.

```{r shorten-tukey, fig.cap="Heatmap showing the Tukey test results from the ANOVAs run on the climatologies generated from all possible time series lengths (i.e. 3 -- 34 years). The different sites are shown as different rows of panels, and the different climatologies (seasonal signal and 90th percentile threshold, from both normal and detrended time series) are shown as different columns. The X and Y axes here denote two different start years for time series being compared. For example, a pixel at '1990' on the X axis, and '2010' on the Y axis is showing the difference (_p_-value) between the climatology generated from a time series from 1990 -- 2014 against the climatology from the same time series that runs only from 2010 -- 2014. Significant differences are marked with a small black dot. Note that results tend not to differ significantly once the time series being compared are more than several years long."}
sst_ALL_both_clim_tukey <- clim_tukey(sst_ALL_both_clim) %>% 
  tidyr::separate(col = comparison, into = c("comp1", "comp2")) %>% 
  mutate(comp1 = as.numeric(comp1), 
         comp2 = as.numeric(comp2))

ggplot(sst_ALL_both_clim_tukey, aes(x = comp2, y = comp1)) +
  geom_tile(aes(fill = adj.p.value)) +
  geom_point(data = filter(sst_ALL_both_clim_tukey, adj.p.value <= 0.05),
             size = 0.01) +
  # geom_text(aes(label = round(adj.p.value, 2))) +
  scale_fill_gradient2(midpoint = 0.1) +
  coord_equal(expand = 0) +
  facet_grid(site~metric+trend) +
  labs(x = "", y = "")
```

The figure above is perhaps a bit odd, but I think a lengthy table would have been less informative. What the figure above is showing is that most time series lengths do not create significantly different results for the calculated climatologies. We also see that even with very short time series (< 10 years), the calculated climatologies tend not to differ from those created from nearby years. The exception to this is the `WA` time series. We may see that the 90th percentile threshold for the three year time series (top row of pixels in the `WA` panels) differs significantly from the ~4 -- 7 year time series, but then does not differ significantly from the much longer time series. This is certainly due to the massive MHW near the end of this time series. It is a good indicator of one of the perils of using such short time series; that one massive event can create significant changes in the results. 


#### Kolmogorov-Smirnov tests

Now knowing that the daily values that make up the climatologies tend to differ based on the number of years used, as seen with the ANOVA and Tukey results, we want to check where the distributions of the climatologies themselves begin to differ. We will do this through a series of pair-wise two-sample KS tests.

```{r KS-clims, fig.cap="Heatmap showing the results of pairwise Kolmogorov-Smirnoff tests for the climatologies from the same time series at differing lengths. Small black dots denote significant differences (_p_-value <= 0.05."}
# Extract climatology values only
sst_ALL_both_clim_only <- sst_ALL_both_clim %>% 
  select(-t, -temp) %>% 
  unique() %>% 
  arrange(site, trend, year_index, doy)

KS_sub <- function(df, year_index_1, year_index_2){
  df_1 <- df %>% 
    filter(year_index == year_index_1)
  df_2 <- df %>% 
    filter(year_index == year_index_2)
  res <- data.frame(seas = round(ks.test(df_1$seas, df_2$seas)$p.value, 4),
                    thresh = round(ks.test(df_1$thresh, df_2$thresh)$p.value, 4),
                    year_1 = year_index_1,
                    year_2 = year_index_2)
  return(res)
}

# The KS results
sst_ALL_both_clim_KS_p <- data.frame()
for(i in 1:length(unique(sst_ALL_both_clim_only$year_index))){
  year_index_1 <- unique(sst_ALL_both_clim_only$year_index)[i]
  for(j in 1:length(unique(sst_ALL_both_clim_only$year_index))){
    year_index_2 <- unique(sst_ALL_both_clim_only$year_index)[j]
    if(year_index_1 < year_index_2){
      suppressWarnings(
      res <- sst_ALL_both_clim_only %>% 
        group_by(site, trend) %>% 
        do(KS_sub(., year_index_1 = year_index_1, year_index_2 = year_index_2)) %>% 
        ungroup() %>% 
        as.tibble(.)
      )
      sst_ALL_both_clim_KS_p <- rbind(sst_ALL_both_clim_KS_p, res)
    }
  }
}

sst_ALL_both_clim_KS_p_long <- sst_ALL_both_clim_KS_p %>% 
  tidyr::gather(key = "metric", value = "p.value", -site, -trend, -year_1, -year_2)

ggplot(sst_ALL_both_clim_KS_p_long, aes(x = year_1, y = year_2)) +
  geom_tile(aes(fill = p.value)) +
  geom_point(data = filter(sst_ALL_both_clim_KS_p_long, p.value <= 0.05),
             size = 0.01) +
  # geom_text(aes(label = round(adj.p.value, 2))) +
  scale_fill_gradient2(midpoint = 0.1) +
  coord_equal(expand = 0) +
  facet_grid(site~metric+trend) +
  labs(x = "", y = "")
```

The table above shows that while climatology values only generated from short time series against long time series tend to be significantly different when tested with an ANOVA, Kolmogorov-Smirnov tests on the shape of these distributions say otherwise. For the `WA` time series, nearly any comparison being made will show that the climatology distributions are significantly different. However, we also see different patterns in each of the other two time series. These results do not show one clear pattern and so one is left to wonder how representative these results are. This will require that this analysis be run on a global scale as well.


### MHW metrics

#### ANOVA

With the effects of shortened time series on the calculation of climatologies quantified, we will now compare the results of the MHWs detected using an ANOVA. Unfortunately, in order to make a direct comparison of all of the MHW detected in the different time series lengths, we may only use the date range for the shortest time series used. This means that only events whose peak dates occurred in 2012 -- 2014 will be used.

```{r compare-shorten}
# Calculate events and filter only those from 2002 -- 2011
sst_ALL_both_event <- sst_ALL_both_clim %>% 
  group_by(site, trend, year_index) %>% 
  nest() %>% 
  mutate(res = map(data, detect_event_event)) %>% 
  select(-data) %>% 
  unnest(res) #%>% 
  # filter(date_start >= "2002-01-01", date_end <= "2011-12-31") %>% 
  # select(-c(index_start:index_end, date_start:date_end))
```
```{r compare-shorten-p, fig.cap="Heatmap showing the ANOVA results for the comparisons of the main four MHW metrics from events that peaked in the years 2012 -- 2014 from all time series lengths, both with and without the long-term trend removed."}
# ANOVA p
sst_ALL_both_event_aov_p <- sst_ALL_both_event %>% 
  filter(lubridate::year(date_peak) >= 2012) %>% 
  select(site, trend, year_index, duration, intensity_mean, intensity_max, intensity_cumulative) %>% 
  nest(-site, -trend) %>%
  mutate(res = map(data, event_aov_p)) %>% 
  select(-data) %>% 
  unnest() #%>% 
  # spread(key = metric, value = p.value)

# visualise
ggplot(sst_ALL_both_event_aov_p, aes(x = site, y = metric)) +
  geom_tile(aes(fill = p.value)) +
  geom_text(aes(label = round(p.value, 2))) +
  scale_fill_gradient2(midpoint = 0.1) +
  theme(axis.text.y = element_text(angle = 75, hjust = 0.5)) +
  facet_wrap(~trend)
```

The heatmap above shows us that the removal of the long-term trend in the time series often has a significant impact on how much the detected MHWs may differ depending on time series length. Curiously, detrending the time series actually makes the differences between the max and mean intensities not significant for the `NW_Atl` time series. The opposite is true for the other two time series. What's also interesting is that when the trend is left in, none of the MHW metrics for events detected in the `Med` differ significantly, but the removal of the trend causes all of them to become significantly different.


#### Post-hoc Tukey test

It should not be surprising that comparing events detected from a climatology based on three years of data may differ significantly from those based on 34 years of data. Where the differences emerge is the real question. And to find this out we will use a post-hoc TUkey test, as done for the climatologies above.

```{r shorten-event-tukey, fig.cap="Heatmap showing the Tukey test results from the ANOVAs run on the MHW metrics generated from all possible time series lengths (i.e. 3 -- 34 years). The different sites are shown as different rows of panels, and the different climatologies (seasonal signal and 90th percentile threshold, from both normal and detrended time series) are shown as different columns. The X and Y axes here denote two different start years for time series being compared. For example, a pixel at '1990' on the X axis, and '2010' on the Y axis is showing the difference (_p_-value) between the climatology generated from a time series from 1990 -- 2014 against the climatology from the same time series that runs only from 2010 -- 2014. Significant differences are marked with a small black dot."}
sst_ALL_both_event_tukey <- sst_ALL_both_event %>%
  filter(lubridate::year(date_peak) >= 2012) %>% 
  select(site, trend, year_index, duration, intensity_mean, intensity_max, intensity_cumulative) %>% 
  mutate(year_index = as.factor(year_index)) %>% 
  group_by(site, trend) %>% 
  nest() %>% 
  mutate(res = map(data, event_aov_tukey)) %>% 
  select(-data) %>% 
  unnest() %>% 
  tidyr::separate(col = comparison, into = c("comp1", "comp2")) %>% 
  mutate(comp1 = as.numeric(comp1), 
         comp2 = as.numeric(comp2))

ggplot(sst_ALL_both_event_tukey, aes(x = comp2, y = comp1)) +
  geom_tile(aes(fill = adj.p.value)) +
  geom_point(data = filter(sst_ALL_both_event_tukey, adj.p.value <= 0.05),
             size = 0.01) +
  # geom_text(aes(label = round(adj.p.value, 2))) +
  scale_fill_gradient2(midpoint = 0.1) +
  coord_equal(expand = 0) +
  facet_grid(site~metric+trend) +
  labs(x = "", y = "")
```

The results of the Tukey tests shown above demonstrate that, except for one comparison, the differences between the events detected with different time series lengths do not differ significantly on a pairwise basis. There are however some interesting artifacts in the results that seem to show that some dramatic events may be having a large impact on how the results compare against one another.


#### Confidence intervals

```{r event-CI-plot1, fig.cap="Confidence intervals of the different metrics for each of the shortened time series. Each panel shows the results for one of four MHW metrics. The X axis shows which year the time series began that the CI bars are representing, and the Y axis shows the spread of the confidence around the population mean of the MHW metric. The bottom row of panels shows the count of events detected from 2012 -- 2014, depending on what the climatology period was, as seen on the X axis."}
# ANOVA CI
sst_ALL_both_event_CI <- sst_ALL_both_event %>% 
  filter(lubridate::year(date_peak) >= 2012) %>% 
  select(site, trend, year_index, duration, intensity_mean, intensity_max, intensity_cumulative) %>% 
  nest(-site, -trend) %>%
  mutate(res = map(data, event_aov_CI)) %>% 
  select(-data) %>% 
  unnest()

CI_plot_1 <- ggplot(sst_ALL_both_event_CI, aes(x = year_index)) +
  geom_errorbar(width = 1, alpha = 0.8,
                aes(ymin = lower, ymax = upper, linetype = trend)) +
  # geom_text(aes(label = n, y = upper*1.3, colour = trend), size = 3) +
  geom_point(aes(y = mid, colour = trend), size = 1, alpha = 0.7) +
  facet_grid(metric~site, scales = "free_y") +
  labs(x = "start year", y = "value")
# CI_plot_1
CI_plot_1.1 <- ggplot(filter(sst_ALL_both_event_CI, metric == "duration"), 
                      aes(x = year_index, y = n, fill = trend)) +
  geom_bar(stat = "identity", position = "identity", alpha = 0.6) +
  # geom_text(aes(label = n, y = upper*1.3, colour = trend), size = 3) +
  # geom_point(aes(y = mid, colour = trend), size = 1, alpha = 0.7) +
  facet_wrap(~site) +
  labs(x = "start year", y = "event count (n)")
# CI_plot_1.1
ggarrange(CI_plot_1, CI_plot_1.1, ncol = 1, nrow = 2, common.legend = T, heights = c(1, 0.5))
```

Please note that the events being compared here, and so the CIs seen above, are only for those with peak dates in the years 2012 -- 2014 so as not to violate the assumption that the sample sizes are similar. Therefore the overall number of events tends to be lower, which has led me to use basic bootstrapping to create the CIs above. This figure is rather busy, but we see on the bottom row that nearly twice as many MHWs were detected in the `NW_Atl` than the other two time series. This trend tends to hold true for all of the CIs. So when fewer events are detected, the CIs spread out. Looking at the top four rows we also see that when more years of data are used to calculate the climatologies with detrended data, fewer events are detected, but they tend to be stronger/longer. These differences generally do not appear to be significant.
