---
title: "Default MHW outputs in R and Python"
author: "Robert W Schlegel"
date: "`r Sys.Date()`"
description: "This vignette compares the code/work flow one would use to calculate default (Hobday et al. 2016) MHWs in both R and Python as well as the different outputs and speeds."
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
bibliography: bibliography.bib
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 4, fig.align = 'center',
                      warning = FALSE, message = FALSE, 
                      tidy = FALSE)
options(scipen=999)
```

## Overview

The purpose of this vignette is to walk one through how to calculate MHWs in both the R and Python languages. It will use code from both languages throughout. The secondary purpose of this vignette is to show that the outputs are identical. The tertiary purpose of this vignette is to run benchmarks on the code to compare their speeds.

## Calculating events

First up, let's look at the two different ways in which one may calculate MHWs. First up, the R code, then Python.

### R code

#### Setup

The basic functionality for calculating marine heatwaves (MHWs) in R may be found in the __`heatwaveR`__ package that may currently be downloaded and installed with the following lines of code. Note that if one has already installed these packages they do not need to be installed again. To run one of the lines in the following code chunk will require that the hash-tag first be removed.

```{r r-packages}
# install.packages("devtools")
## Development version from GitHub
# devtools::install_github("robwschlegel/heatwaveR") 
## Stable version from rOpenSci
## Currently not available
## Stable version from CRAN
# install.packages("heatwaveR") # Currently not available
```

With the necessary packages installed, we activate `heatwaveR` with the following line of code.

```{r r-init}
library(heatwaveR)
```

#### Default output

With everything downloaded and ready for us to use we may now calculate some events. The `heatwaveR` package has three built in time series (`sst_WA`, `sst_Med`, `sst_NW_Atl`) that we may use to more easily demonstrate how the code works. The general pipeline in `R` for calculating events is first to create a climatology from a chosen time series using `ts2clm()`, and then to feed that output into `detect_event()`, as seen below.

```{r r-default}
# First we create a default climatology as outlined in Hobday et al. (2016)
ts_clim <- ts2clm(data = sst_WA, climatologyPeriod = c("1982-01-01", "2014-12-31"))

# Then we feed that object into the second and final function
res <- detect_event(ts_clim)
```

To look at these outputs we would use the following options. For now we'll just look at the event output.

```{r r-view}
# Look at the top six rows of the first 6 columns of the events
res$event[1:6, 1:6]

# Or perhaps the most intense event
res$event[res$event$intensity_max == max(res$event$intensity_max), 1:6]
```

### Python code

```{r python-setup, include = FALSE}
# devtools::install_github("rstudio/reticulate")
library(reticulate)
use_condaenv("py27")
```

#### Setup

To download and install the Python package for calculating MHWs one may run the following line of code in a console:

```{r}
# Note that the hashtag must be removed in order
# pip install git+git://github.com/ecjoliver/marineHeatWaves@master
```

Or simply download the [GitHub repository](https://github.com/ecjoliver/marineHeatWaves) and follow the instructions there for downloading. Or if still lost, phone a friend!

Before we begin the calculations we need to create a time series. I've chosen to take the `sst_WA` time series from the __`heatwaveR`__ package to ensure consistency between the results. For ease of use I simply saved this object as a csv file on my computer and loaded it back in to Python.

```{r python-prep}
ts <- sst_WA
# Write out only a vector of temperatures
write.csv(ts$temp, "data/sst_WA.csv", row.names = FALSE)
```


#### Default calculations

With the package installed it is then activated and run as follows:

```{python}
# Required for data prep and export
import numpy as np
from datetime import date
import pandas as pd

# The MHW functions
import marineHeatWaves as mhw

# The date values
t = np.arange(date(1982,1,1).toordinal(),date(2014,12,31).toordinal()+1)

# The temperature values
sst = np.loadtxt("data/sst_WA.csv", delimiter=',', skiprows=1) # because a heading row needs to be skipped

# The event metrics
mhws, clim = mhw.detect(t, sst)

# Save event results
mhws_df = pd.DataFrame.from_dict(mhws)
mhws_df.to_csv('data/mhws_py.csv', sep = ',', index=False)

# Save climatology results
clim_df = pd.DataFrame.from_dict(clim)
clim_df.to_csv('data/clim_py.csv', sep = ',', index=False)
```

### Reticulate code

It is also possible to run the Python code through R with the use of the R package __`reticulate`__. This is particularly useful as it allows us to perform the comparisons and benchmarking all within the same language.

#### Setup

Here we load the __`reticulate`__ package and choose the conda environment I've already created called `py27`. For help on how to set up a conda environment go [here](https://conda.io/docs/user-guide/tasks/manage-environments.html). I've ensured that all of the required python modules are installed within this environment.

```{r, eval=FALSE}
# install.packages("reticulate")
library(reticulate)
use_condaenv("py27")
```

Once we've told R which version/environment we would like to use for Python we may then load the necessary modules.

```{r python-modules, eval=FALSE}
np <- import("numpy")
datetime <- import("datetime")
mhw <- import("marineHeatWaves")
```

One may run python code in it's native form within R by passing it as a character vector to `py_run_string()`.

```{r python-strings, error=TRUE, eval=FALSE}
py_run_string("x = 10")
py_run_string("t = np.arange(date(1982,1,1).toordinal(),date(2014,12,31).toordinal()+1)")
py_run_string("sst = np.loadtxt(open('data/sst_WA.csv', 'r'), delimiter=',', skiprows=1)")
```

#### Default calculations

```{r python-code, error=TRUE, eval=FALSE}
# These numbers were taken from print(t) in the python code above
t <- as.integer(np$array(seq(723546, 735598)))
sst <- np$array(sst_WA$temp)
res_python <- mhw$detect(t = py$t, temp = py$sst) # There appears to be an Rcpp issue preventing this from handshaking...
# The reticulate package is still in development...
```

## Comparisons

With some climatologies and events calculated with both languages we may now compare the results of the two. I'll do so here natively in R to avoid any potential hiccups from translating across languages. I'll create the R output here, and load the Python output created above.

```{r load-comparisons}
# Load libraries for data manipulation and visualisation
library(tidyverse)

# Set R results
res_event_R <- res$event
res_clim_R <- res$climatology

# Set Python results
res_event_Python <- read_csv("data/mhws_py.csv")
res_clim_Python <- read_csv("data/clim_py.csv")
```

With these default results loaded in the same format in the same language we can now start to look at how they stack up. For starters I am just doing some simple sums and correlations.

### Climatologies

```{r}
cor(res_clim_R$seas, res_clim_Python$seas)
sum(res_clim_R$seas) - sum(res_clim_Python$seas)
cor(res_clim_R$thresh, res_clim_Python$thresh)
sum(res_clim_R$thresh) - sum(res_clim_Python$thresh)
```

The seasonal and threshold climatologies correlate very well, but adding them up we see that the Python values are consistently higher. This is due to rounding differences between the languages. Now for the events.

### Events

First we peek at a few specific values of interest.

```{r}
cor(res_event_R$intensity_max, res_event_Python$intensity_max)
sum(res_event_R$intensity_max) - sum(res_event_Python$intensity_max)
cor(res_event_R$intensity_var, res_event_Python$intensity_var)
sum(res_event_R$intensity_var) - sum(res_event_Python$intensity_var)
cor(res_event_R$rate_onset, res_event_Python$rate_onset)
sum(res_event_R$rate_onset) - sum(res_event_Python$rate_onset)
cor(res_event_R$rate_decline, res_event_Python$rate_decline)
sum(res_event_R$rate_decline) - sum(res_event_Python$rate_decline)
```

With that looking fine, we next run a for loop that will run a correlation on all rows with the same name.

```{r}
# Remove non-numeric columns
res_event_num <- res_event_R %>% 
  select_if(is.numeric)

# Run the loop
res_event <- data.frame()
for(i in 1:length(colnames(res_event_num))){
  if(colnames(res_event_num)[i] %in% colnames(res_event_Python)){
    x1 <- res_event_R[colnames(res_event_R) == colnames(res_event_num)[i]]
    x2 <- res_event_Python[colnames(res_event_Python) == colnames(res_event_num)[i]]
    x <- data.frame(r = cor(x1, x2, use = "complete.obs"),
                    difference = round(sum(x1, na.rm = T) - sum(x2, na.rm = T), 4),
                    var = colnames(res_event_num)[i])
    colnames(x)[1] <- "r"
    rownames(x) <- NULL
    } else {
      x <- data.frame(r = NA, difference = NA, var = colnames(res_event_num)[i])
      }
  res_event <- rbind(res_event, x)
  }
res_event
```

With all of our overlapping columns compared, and our differences and Pearson r values looking solid, let's finish off this basic comparison by finding which columns are not shared between the different language outputs. Also, please note that the apparently large differences between the `index_start`, `index_peak`, and `index_end` values are due to the different indexing methods of R and Python. R starts at 1 and Python at 0.

```{r}
cols_R <- colnames(res_event_R)[!(colnames(res_event_R) %in% colnames(res_event_Python))]
cols_R
cols_Py <- colnames(res_event_Python)[!(colnames(res_event_Python) %in% colnames(res_event_R))]
cols_Py
```

Wonderful! Most things match up nicely. The duration of categories of events is something added in R by another function `category()`, and will be left that way for now. The "time" columns in the Python output aren't relevant as far as I can see in the present usage as these functions currently only take day values. The different methods of labelling the events will be left as they are for now as well.

It is also worth noting that the values for `index_start`, `index_peak`, and `index_end` are off by one between the two languages. This is due to the difference in indexing between the languages. Looking at the `date_start`, `date_peak`, and `date_end` values we see that they are the same.

### Missing data

A bug was discovered in v0.3.3 of the R code with regards to the handling of missing data. Specifically, in the move to a C++ back-end, the R code stopped being able to handle missing data for the climatology calculations. This has since been corrected for is v0.3.4, but it is worthwhile to ensure that missing data are handled the same way.

First we'll create the dataframe with missing data:

```{r missing-data, eval=FALSE}
library(padr)
library(lubridate)
random_knockout <- function(df, prop){
  res <- df %>% 
    sample_frac(size = prop) %>% 
    arrange(t) %>%
    pad(interval = "day")
  return(res)
}

# Remove 10% of the data randomly
sst_WA_miss_random <- random_knockout(sst_WA, 0.9)
write.csv(sst_WA_miss_random$temp, file = "data/sst_WA_miss_random.csv", row.names = F, na = "NaN")

# Remove simulated ice cover
sst_WA_miss_ice <- sst_WA %>% 
  mutate(month = month(t, label = T),
         temp = ifelse(month %in% c("Jan", "Feb", "Mar"), NA, temp)) %>% 
  select(-month)
write.csv(sst_WA_miss_ice$temp, file = "data/sst_WA_miss_ice.csv", row.names = F, na = "NaN")
```

With the missing data saved, we can now calculate and compare the climatologies that the two different languages will create.

```{python}
# Required for data prep and export
import numpy as np
from datetime import date
import pandas as pd

# The MHW functions
import marineHeatWaves as mhw

# The date values
t = np.arange(date(1982,1,1).toordinal(),date(2014,12,31).toordinal()+1)

# The temperature values
sst_random = np.loadtxt("data/sst_WA_miss_random.csv", delimiter = ',', skiprows = 1)
sst_ice = np.loadtxt("data/sst_WA_miss_ice.csv", delimiter = ',', skiprows = 1)

# The event metrics
mhws_random, clim_random = mhw.detect(t, sst_random)
# It appears as though the Python code can't deal with ice coverage...
#mhws_ice, clim_ice = mhw.detect(t, sst_ice)

# Save climatology results
clim_random_df = pd.DataFrame.from_dict(clim_random)
clim_random_df.to_csv('data/clim_py_random.csv', sep = ',', index = False)
#clim_ice_df = pd.DataFrame.from_dict(clim_ice)
#clim_ice_df.to_csv('data/clim_ice_py.csv', sep = ',', index = False)
```

With the Python climatologies calculated from the missing data, we will load the results and compare them to R.

```{r}
# Load and prep missing data
sst_WA_miss_random <- read_csv("data/sst_WA_miss_random.csv") %>% 
  dplyr::rename(temp = x) %>% 
  mutate(t = seq(as.Date("1982-01-01"), as.Date("2014-12-31"), by = "day")) %>% 
  select(t, temp)
sst_WA_miss_random$temp[is.nan(sst_WA_miss_random$temp)] <- NA

# Load Python results
res_clim_random_Python <- read_csv("data/clim_py_random.csv")

# caluclate R climatologies
res_clim_random_R <- ts2clm(sst_WA_miss_random, climatologyPeriod = c("1982-01-01", "2014-12-31"))

# Compare
cor(res_clim_random_R$seas, res_clim_random_Python$seas)
sum(res_clim_random_R$seas) - sum(res_clim_random_Python$seas)
cor(res_clim_random_R$thresh, res_clim_random_Python$thresh)
sum(res_clim_random_R$thresh) - sum(res_clim_random_Python$thresh)
```

We may see from the results above that the values still correlate very strongly, if slightly less so than with no missing data. Whereas the seasonal signal was slightly higher when calculated by the Python code, now the R results are slightly higher. The threshold was higher with Python as well when no data were missing, and now it is even higher. This is a somewhat curious result, but the differences remain much too small to be of any real concern. 

## Benchmarks

The final thing we want to look at in this vignette is the speed differences in calculating MHWs between the two languages.

### R

```{r}
library(microbenchmark)
# The old R code
library(RmarineHeatWaves)
microbenchmark(detect(make_whole(data = sst_WA), climatology_start = "1982-01-01", climatology_end = "2014-12-31"), times = 10)
# The new R code
microbenchmark(detect_event(ts2clm(data = sst_WA, climatologyPeriod = c("1982-01-01", "2014-12-31"), robust = FALSE)), times = 10)
```

### Python

```{python}
import time
total = 0
for i in range(10):
    start = time.clock()
    mhws, clim = mhw.detect(t, sst)
    end = time.clock()
    total += end-start
bench_py = total/10
print(bench_py)
```

The Python code appears to be about twice as fast at ~0.18 seconds to ~0.32 seconds for R. And the Python code is also calculating the event categories, which R is not. That is done in an additional step with `category()`. The R code is however allowing for a wider range of options for climatologies.
