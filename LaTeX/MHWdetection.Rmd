---
title: "Detecting marine heatwaves with sub-optimal data"
author: Robert W. Schlegel1,2,*,#, Eric C. J. Oliver1, Alistair J. Hobday3, Albertus J. Smit2
# date: "April 30th, 2018"
output:
  word_document:
    reference_docx: Frontiers_Template.docx
csl: FMars.csl
bibliography: MHWdetection.bib
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 8, fig.align = 'center',
                      echo = TRUE, warning = FALSE, message = FALSE, 
                      eval = TRUE, tidy = FALSE)
```

1Department of Oceanography, Dalhousie University, Halifax, Nova Scotia, Canada  
2Department of Biodiversity and Conservation Biology, University of the Western Cape, Bellville, South Africa  
3CSIRO Oceans and Atmosphere, Hobart, Tasmania, 7000, Australia

__*Correspondence:__  
Robert Schlegel  
robert.schlegel@dal.ca  
# Currently based at the Department of Physical Oceanography, Woods Hole Oceanographic Institution, Woods Hole, Massachusetts, USA 

__Keywords: marine heatwaves, sea surface temperature, sub-optimal data, time series length, missing data, decadal trend__

# Abstract

Marine heatwaves (MHWs), or prolonged periods of anomalously warm sea water temperature, have been increasing in duration and intensity globally for decades. However, there are many coastal, oceanic, polar, and sub-surface regions where our ability to detect MHWs is uncertain due to limited high quality data. Here we investigate the effect that short time series length, missing data, or linear decadal temperature trends may have on the detection of MHWs. We show that MHWs detected in time series as short as 10 years did not have durations or intensities appreciably different from events detected in a standard 30 year long time series. We also show that the output of our MHW algorithm for time series missing less than 20% data did not differ appreciably from a complete time series, and that the level of allowable missing data could be increased to 40% when gaps were filled by linear interpolation. Finally, linear decadal trends of 0.10°C/dec or greater added to a time series caused larger changes (increases) to the count and duration of detected MHWs than shortening a time series to 10 years or missing more than 20% of the data. Though the decadal trend in a time series has the largest effect on the detection of MHWs, it is also the easiest to correct. Time series length has less of an effect on MHW detection than missing data, but is the most difficult to correct. We provide suggestions for best practices to improve the accuracy of MHW detection with sub-optimal time series and show how the accuracy of these corrections may change regionally.  
<!-- (260 words) -->


# Introduction
  
The idea of locally warm seawater disrupting species distributions or ecosystem functioning is not a novel concept. We have known for decades that transient warm water occurrences in the ocean could result in major impacts on marine ecosystems [e.g. @Baumgartner1992; @Salinger2016]. The study of the effects of anomalously warm seawater temperatures began in earnest in the early 1980's when research into the ENSO phenomenon intensified [e.g. @Philander1983]. After the 1980's, researchers began noticing that warm water events were becoming more frequent and with large ecosystem impacts [e.g. @Dayton1992], but it was not until 2018 that this was demonstrated with global observations [@Oliver2018]. 

In order to quantify the increased occurrence and severity of these events it was necessary to develop a methodology that would be inter-comparable for any location on the globe. This was accomplished in 2016 after the International Working Group on Marine Heatwaves (marineheatwaves.org) initiated a series of workshops to address this issue. This definition for anomalously warm seawater events, known as marine heatwaves (MHWs), has seen wide-spread and rapid adoption due to ease of use and global applicability [@Hobday2016]. One limitation with this algorithm that has not yet been addressed is the assumption that a researcher has access to the highest quality data available when detecting MHWs. In the context of MHW detection, a 'high quality' time series is spatio/temporally consistent, quality controlled, and at least 30 years in length [Table 3 in @Hobday2016]. While not stated explicitly in @Hobday2016, a 'high quality' time series should also not have any missing days of data. To avoid contention on the use of the word 'quality', time series that meet the aforementioned standards are referred to here as 'optimal', whereas those that do not meet one or more of the standards are referred to as 'sub-optimal'. Another unresolved issue with the @Hobday2016 algorithm, which does not fall within the requirements for optimal data, is how much of an effect the long-term (secular) trend in a time series may have on MHWs detected in it when compared to that same time series when the trend has been removed.

<!-- With the advent of remotely-sensed sea surface temperature (SST) products in the early 1980's, oceanographers and other marine stake holders were given a synoptic view of the worlds oceans, no longer relying on ship-based measurements and stationary moorings to infer temperature for meso-scale features and larger.  -->

Most remotely-sensed data, and more recently output from ocean models and reanalyses, consist of over 30 years of data and utilise statistical techniques to fill gaps in their time series from a number of environmental and technical sources. This means that these data are considered optimal for MHW detection. An excellent reference for the remotely-sensed products currently available, as well as their strengths and weaknesses, is provided by @Harrison2019. Even though remotely-sensed data products are considered optimal, they still have other issues (e.g. land bleed, incorrect data flagging, spatial and temporal infilling) and so it may be necessary that for coastal applications researchers utilise sub-optimal data, such as sporadically collected _in situ_ time series [@Smit2013; @Hobday2016].

<!-- RWS: Check that the @Harrison2019 reference came out correctly -->

<!-- RWS: Also need to discuss how the different satellite products provide different resolutions, but at the cost of time series length. -->

<!-- Coastal areas are often poorly sampled yet are the most susceptible to the impacts of MHWs [e.g. @Smale2019] so it is necessary to address the issues that using these data may have on the detection of MHWs. -->

<!-- RWS: Perhaps a bit here about the increased heat content of sub-surface waters and how that makes MHWs below the surface appear to last longer. -->

This paper seeks to understand the limitations the use of sub-optimal data impose on the accurate detection of MHWs. Of primary interest are three key challenges: 

1) The use of time series shorter than 30 years
2) The use of temporally inconsistent (missing data) time series
3) The use of time series in areas with large long-term temperature trends

We use a combination of reference time series from specific locations and global data to address these issues. The effects of the three sub-optimal data challenges on the detection of MHWs are quantified in order to provide researchers with the level of confidence they may express in their results. Where possible, best practices for the correction of these issues are detailed.


# Defining marine heatwaves

The definition used in this paper for a MHW is "a prolonged discrete anomalously warm water event that can be described by its duration, intensity, rate of evolution, and spatial extent." [@Hobday2016]. This qualitative definition is quantified with an algorithm that calculates a suite of metrics. These metrics may then be used to characterise MHWs and allow comparison with ecological impacts. The calculation of these metrics first requires determining the mean and 90th percentile temperature for each calendar day-of-year ('doy') in a time series. The mean 'doy' temperatures, which also represent the seasonal signal in the time series, provide the expected baseline temperature whose daily exceedance is used to calculate the local intensity of MHWs. The 90th percentile 'doy' temperatures serve as the threshold that must be exceeded for 5 or more consecutive days for the anomalously warm temperatures to be classified as a MHW and for the calculation of the additional MHW metrics.

In this paper we focus on the three metrics that succinctly summarise a MHW, of the set described in Table 2 of @Hobday2016. The first metric, _duration_, is defined as the period of time that the temperature remains at or above the 90th percentile threshold without dipping below it for more than 2 consecutive days. The duration of an event may be used as a measurement of the chronic stress that a MHW may inflict upon a target species or ecosystem [e.g. @Oliver2017; @Smale2019]. The second metric, _maximum intensity_, is the largest temperature anomaly during the event and is calculated by subtracting the climatological mean 'doy' temperature from the recorded temperature on that day. This metric may be used as a measurement of acute stress [e.g. @Oliver2017; @Smale2019]. A third metric, _cumulative intensity_, is used to determine the 'largest' MHW in a time series (see Methods). This metric is the integral of the temperature anomalies of a MHW, and so has units of °C-days not °C, but represents the sum of temperature anomalies over the duration of the MHW, therefore; cumulative intensity is comparable to the degree heating days metric used in coral reef studies [@Fordyce2019]. 

<!-- RWS: From IPCC SROCC: "To monitor and predict coral bleaching risk, the metric degree heating week (DHW; e.g., Eakin et al., 2010) is often used, which combines the effect of duration and magnitude of the heatwave." -->

<!-- RWS: From IPCC SROCC: "The DHW describes how much heat has accumulated in an area over the past twelve weeks by adding up any temperatures that exceed 1°C above the maximum summertime mean (e.g., Eakin et al., 2010)" -->

<!-- @Hobday2018 extended the MHW definition to include a categorisation scheme based on the intensity of an event. These categories were: I Moderate, II Strong, III Severe, and IV Extreme. The category of an event is determined by how many times the maximum intensity of the MHW is a multiple of the difference between the mean and 90th percentile doy temperatures (Figure 1). For example, if the difference between the mean and 90th percentile doy temperatures on the warmest day of a MHW is 1.5°C, and the temperature recorded on that warmest day was 3°C warmer than the mean doy temperature for that day, this would be considered a category II (Strong) MHW. Were the maximum temperature to be recorded at 4.5°C, this would be classified as a category III Severe MHW. To provide a more robust category quantification of a MHW, the categories are also calculated for each day of the event to provide a proportion of the days during which the MHW was within each of the categories. See Table 2 in @Hobday2018 for further examples. -->

We used the R implementation of the @Hobday2016 MHW definition, which is available in python (<https://github.com/ecjoliver/marineHeatWaves>), R [@Schlegel2018], and MATLAB [@Zhao2019]. We compared the R and python default outputs, assessed how changing the arguments affected the results, and compared the other functionality provided between the two languages. While some style differences exist as a result of the functionality of the languages, the climatology outputs are identical to within < 0.001°C per day-of-year ('doy'). An independent analysis of the Python and MATLAB results also confirmed that they were functionally identical (pers. com. Zijie Zhao; MATLAB distribution author).

<!-- Due to the availability, ease of use, and interoperability of this methodology it has seen rapid uptake across marine sciences [@Hobday2018], although other definitions have been used [e.g. @Frolicher2018].  -->

<!-- The increased use of the @Hobday2016 and @Hobday2018 methodologies has introduced a new series of meta-issues in that different groups often depart from the default use of the algorithm for MHW detection in varying degrees [e.g. Darmaraki2019, Guillen2019], or simply use entirely different methodologies [e.g. @Frolicher2018] while referring to the @Hobday2016 definition. -->

<!-- What should researchers do if faced with a particular challenge, such as wanting to use a daily collected _in situ_ time series of bottom temperatures that is only 15 years long? Are results significantly different when using a time series that is collected by hand during only weekdays, and not weekends (29% missing data)? Or to that end, is it even possible to use a time series with only one temperature value per week (86% missing data)? -->

<!-- Here we explore methods that can improve the use of the @Hobday2016 and @Hobday2018 methodology, ensuring that results remain comparable if performed with data that do not meet the minimum requirements of 30 years length that were first suggested, and data with large proportions of missing values.  -->


# What are optimal data for detecting marine heatwaves?

When working with extreme values in a time series, such as MHWs, it is important that the quality of the data are high [@Hobday2016]. @Hobday2016 stated that high quality data, referred to here as 'optimal', used for the detection of MHWs should meet the following criteria: 

1) A time series length of at least 30 years 
2) Quality controlled  
3) Spatially and temporally consistent  
4) Be of the highest spatial and temporal resolution possible/available  
5) _In situ_ data should be used to compliment remotely sensed data where possible  

Although the authors did not specifically state that time series must not contain large proportions of missing data, it can be inferred from the aforementioned requirements and the nature of the proposed algorithm. Another issue affecting the accurate detection of MHWs not discussed in @Hobday2016 is the presence of long-term trends in a time series. @Oliver2018 have shown how dominant the climate change signal can be in the detection of MHWs and we seek to quantify this effect here.

A time series with a sub-optimal length may impact the detection of MHWs by negatively affecting the creation of the daily climatology relative to which MHWs are detected in two primary ways. The first is that with fewer years of data to draw from, the presence of an anomalously warm or cold year will have a larger effect on the climatology than with a sample size of 30 years. The second cause is that because the world is generally warming [@IPCC2014], the use of a shorter time series will almost certainly introduce a warm bias into the results. This means, counterintuitively, that the MHWs detected in a shorter time series will appear to be cooler than the same MHWs detected in a longer time series. This is because the average temperature in a time series consisting of recent data will likely be warmer, which will raise the 90th percentile relative to the observed temperatures and cause the reported MHW metrics to diminish in intensity.

The climatology derived from a time series serves two main roles [@WMO2017]; 1) it serves as a 'benchmark' relative to which past and future measurements can be compared, and against which anomalies can be calculated, 2) it reflects the typical conditions likely to be experienced at a particular place at a particular time. The WMO Guide to Climatological Practices [@WMO2011] stipulate that daily climatologies (which they call 'climate normals') must be based on the most recent 30-year period that ends on a complete decade (currently 1981 -- 2010). The suggested length of a time series for MHW detection was based on this WMO guideline [@Hobday2016].
<!-- RWS: Check that the WMO citations come out correctly. May want to rather include this reference as a footnote as is done in Hobday2016 -->
<!-- RWS: Also, this may no longer be useful. Or at least it may need to be rewritten to better reflect how clim base periods are used in the methods. -->
<!-- RWS: Will probably want to say how, when one has fewer than 30 years of data, one should just use the whole period. -->

Some remotely sensed products suffer from 'gappiness' that result in missing data. This may be due to cloud cover, the presence of sea ice, unsuitable sea states, etc., which become more prevalent at smaller scales, particularly nearer the coast. Some products interpolate to fill missing data gaps, but this results in smoothed sea surface temperature (SST) fields that may mask small-scale spatial variations in surface temperatures. Remotely sensed products may also fill gaps by blending with data from other products, which may introduce other biases. It has been demonstrated that coastal SST pixels from remotely-sensed products may have biases in excess of 5°C from _in situ_ collected data [@Smit2013] however; there is also research that has shown there may be no bias between these different data types [@Smale2009; @Stobart2016]. This is why the use of imperfect _in situ_ collected time series may be needed for coastal MHW applications. These data are also prone to large gaps and so issues with regards to accurate MHW detection are also uncertain. It must be stressed here that the methods proposed in the Best Practices section for working with sub-optimal data do not address the issues that remotely-sensed data have near coastlines.


# Methods

To quantify the effects that time series length, missing data, and long-term trends have on MHW detection we compare the count, duration (days), and maximum intensity (°C) of MHWs from time series as they become increasingly sub-optimal. To ensure approximately equal sample sizes across all tests, only the results for MHWs in the final 10 years of data (2009 -- 2018) are used for each increasingly sub-optimal time series. The single largest MHW in each time series, as determined by cumulative intensity, is also drawn from the same ten year sample.

We then use the following two questions to frame the results:  
  
1) By what percent are the MHW results changed by the increasingly sub-optimal data?
    - For example, when 20% of a time series is missing, how much might the maximum intensity of a single MHW be effected compared to that same MHW when detected in the same time series with no missing data?
2) Do sub-optimal data change the results the same everywhere in the world, or do they differ based on some regional oceanographic characteristics?
    - For example, when a time series has a long-term trend of 0.2°C/dec in an eastern boundary upwelling system (EBUS), does the effect this have on the duration of the detected MHWs differ from the same trend in a time series in a western boundary current (WBC)?

To answer these two questions we use the remotely sensed NOAA OISST dataset [@Reynolds2007; @Banzon2016]. This daily remotely-sensed global SST product has a 1/4 degree spatial resolution with 1982 the first full year of sampling. These data are interpolated and where possible verified against a database of _in situ_ collected temperatures so that the final product does not have any spatial or temporal gaps. The NOAA OISST dataset was used during the creation of the MHW algorithm in @Hobday2016 and so we use it here for consistency. Before being used in this study, the time series at each location (pixel) is de-trended by fitting a simple linear model and removing the residuals from the data. This must be performed so that we may control for the effects of time series length and decadal trend separately. Once de-trended, each time series is treated to the suite of sub-optimal controls (see following sub-sections) and the desired results itemised above are extracted. In order to ensure as much consistency as possible across all test results, the entire duration of the time series is used as the climatology base period, and not the 30 year standard recommended by the WMO. Appendix 1 reports the difference between results when using a 30 year base period versus a 37 year base period.

<!-- RWS: Ensure that this final sentence is correct -->

<!-- Significant differences in MHWs from the time series with different sub-optimal tests are tested by comparing them against the same optimal reference time series (i.e. 30 year length, no missing data, no long-term trend) with a pairwise post-hoc Kruskal-Wallis test [@Siegel1988]. This non-parametric test looks for differences between the central tendency of a control and a series of comparison sets of data, providing the probability (_p_-value) that the sets of data have been drawn from the same pool. It was necessary to use a non-parametric test because we cannot ensure that the data being compared are always normally distributed or have a similar count of observations. The inclusion of a _p_-value in this way is important to frame the results, but we do not use an arbitrary _p_-value threshold to reject a null hypothesis that the outputs from the sub-optimal data are different from the optimal data because testing for null hypotheses in this way is problematic [@Wasserstein2019]. That being said, we will still highlight comparisons that generate a _p_-value of 0.05 or less.  -->

The amount of uncertainty that the sub-optimal tests introduce into the results is calculated by measuring the percent of change in the results from the control (optimal) time series as the data become more sub-optimal. This measurement is performed on the count, sum of duration, and the mean maximum intensity of MHWs detected in the final 10 years of data and the single largest MHW. No significance test is used here, rather the range of change in these values is shown in order to provide a benchmark against which one may decide how much change is too much. Linear models are used to quantify the rates of change that these sub-optimal tests introduce and these trends are analysed at a global scale to investigate spatial patterns.

The answer to the first question posed above is highlighted with the three reference OISST time series from @Hobday2016. These time series are taken from the coast of Western Australia (WA; Figure 1A), the Northwest Atlantic Ocean (NWA; Figure 1B), and the Mediterranean Sea (Med; Figure 1C). These time series are used here for ease of reproducibility and because they each contain a MHW that has been the focus of multiple publications [e.g. @Garrabou2009; @Wernberg2012a; @Mills2013]. The effect of the sub-optimal tests on these three time series are overlaid on 100 randomly selected pixels from the global OISST dataset to show a range of results.

<!-- Figure 1 -->

While not a specific focus in this study, the effects that the sub-optimal tests have on the seasonal mean and threshold climatologies have been included in Appendix 1.

The following three sub-sections describe how the three sub-optimal time series tests are developed. 


## Controlling for time series length

There are currently 37 complete years of data available in the NOAA OISST dataset (1982 -- 2018). In order to determine the effect that time series length has on the focus output we systematically shorten each time series one year at a time from 37 years down to 10 years (2009 -- 2018), before running the MHW detection algorithm. The MHW results for each one year step for each of the time series are then compared against the output from the 30 year (1989 -- 2018) version of the same time series.

In order to ensure equitable sample sizes we only comparing the MHW metrics for events detected within the last 10 years of each test as this is the period of time during which all of the different tests overlap. This is also why we limited the shortening of the time series lengths to 10 years, so that we would still have a reasonable sample size to draw from. 

Because the lengths of the time series were being varied, and were usually less than 30 years in length, it was also necessary that the climatology periods vary likewise. To maintain consistency across the results we use the full range of years within each shortened time series to determine the climatology. For example, if the time series had been shortened from 37 to 32 years (1987 -- 2018), the 32 year period was used to create the climatology. If the shortened time series was 15 years long (2004 -- 2018), this base period was used. The control time series were those with a 30 year length ending in the most recent full year of data available (1989 -- 2018). Note that due to necessity this differs from the climatology period of 1982 -- 2011 that would most closely match the WMO standard. The effect of shifting the 30 year climatology base is discussed in Appendix 1.

The _a-priori_ fix proposed to address the issue of short time series length is to use a different climatology estimation technique. The option currently available within the MHW detection algorithm is to expand the window half width used when smoothing the climatology. Other techniques, such as harmonic regression/Fourier analysis, would have a similar effect but are not used here in favour of the @Hobday2016 method. It is beyond the scope of this paper to compare every possible climatology calculation technique.


## Controlling for missing data

In order to determine the effect of random missing data on the MHW results, each time series has 0 -- 50% of its data removed in 1% steps before running the MHW algorithm. The control time series are the complete versions.

The _a-priori_ fix for missing data in the time series is to linearly interpolate over any gaps. There are many methods of interpolating (imputing) gaps in time series, such as spline interpolation, but we choose linear interpolation here due to its speed, simplicity, and the lack of assumptions it imposes on the data. It is beyond the scope of this paper to account for every possible method of interpolation however; we also count the lengths of the gaps over which data are interpolated in order to show for how many consecutive missing days interpolation begins to fail.


## Controlling for long-term trends

To quantify the effect of long-term (secular) trends on the MHW results we add linear trends of 0.00 -- 0.30°C/dec in 0.01°C/dec steps to each time series. The control time series are those with no added trend (e.g. 0.00°C/dec).

There is no proposed _a-priori_ method to correct for the added linear trend in these data as this would be simply not to add a trend. Rather it is proposed that the relationship between the slope of the added trend and the results it has on the focus outputs be documented to determine if a predictable relationship may be used to correct the results _post-hoc_.


# Results

## Time series length

Shortening the length of a time series from 30 to 10 years had an unpredictable effect on the count of MHWs detected in the most recent 10 years of data (Figure 2A). At 10 years in length, 90% of the pixels tested had between 10 more to 9 fewer MHWs than the 30 year control. The increase or decrease in the count of MHWs for each time series was close to linear, meaning that one may be able to say what the change in the count of MHWs may be as a time series is shortened, but it does not allow us to say if this change is positive or negative. The change in the sum of the MHW days for a 10 year time series ranges primarily from 49% fewer to 59% more than the 30 year control (Figure 2D). This change is slightly more linear than for the count of MHWs, but again, the values may increase or decrease. The mean of the maximum intensities of the sample MHWs also either increase or decrease, with 10 year time series having mean intensities anywhere from 13% less to 5% more than the 30 year control. 
<!-- There is no threshold where any of these samples become significantly different (_p_-value <= 0.05) from the control sample. -->

<!-- Figure 2 -->

Increasing the climatology period longer than 30 years had almost as rapid an effect on creating dissimilar outputs as using fewer years of data. This result stresses the importance of adhering to the WMO standard as closely as possible to ensure the comparability of results. It also demonstrates the arbitrariness of the 30 year climatological base period.

Shortening time series length tended to decrease both the duration and maximum intensity of the largest MHW from each time series (Figure 3D and 3G), while the count of MHWs within the duration of the focus MHW increases (Figure 3A). This is because shortening a time series may increase the seasonal or threshold climatologies, so the shorter a time series becomes, the lower the maximum intensity and shorter the duration of the MHWs may become. MHWs with many spikes, rather than a smooth hump, will be particularly affected by this change in the climatology as it will break one MHW into smaller events, as shown by the increase in MHW count in Figure 3A.

<!-- Figure 3 -->

There are clear global patterns in the changes in MHW results as time series are shortened from 30 to 10 years (Figure 4). The median change in the count of MHWs due to changes in time series length is nearly 0, but much of the western Pacific and northern Atlantic oceans show large rates of increasing MHW counts as time series are shortened (Figure 4A). The rates of change in the eastern Pacific, southern Atlantic, and the Indian Ocean show a mix of both increasing and decreasing counts of MHWs as time series become shorter. The patterns of change in the sum of MHW days closely resemble the change in the count of MHWs (Figure 4B). The decreasing maximum intensities of MHWs caused by decreasing time series lengths were also generally seen to occur throughout the oceans (Figure 4C). The median rate of change in the maximum intensity of MHWs caused by decreasing time series length from 30 to 10 years is seen to be 0.21% per year. This means that, on average, a MHW detected in a 10 year time series will have a maximum intensity about 8.4% cooler than a MHW detected in a 30 year time series (0.21%/year times 20 year difference). This small difference shows the robustness of the MHW detection algorithm. There are areas where decreasing a time series tends to increase the maximum intensities of the MHWs detected. These areas are roughly the same regions where the shortening of a time series causes a decrease in the count of MHW days detected. It is important to note that the long-term trends in these data were removed beforehand so the patterns observed in Figure 4 are due to the properties of the time series themselves and not the climate change signal that would otherwise be dominant in the results.

<!-- Figure 4 -->

The same global patterns in the effect of shortened time series on all MHWs in the final 10 years of data are roughly seen in the effects on the largest MHW. Much of the ocean that shows a decrease in the count of MHWs as a time series is shortened (Figure 4A) also show an increase in the count of MHWs during the duration of the largest MHW at 0.1 additional MHWs per year the time series is shortened (Figure 4D). This may at first seem contradictory, but this increase in the count of MHWs during the largest MHW in a time series is due to the single large MHW being broken into smaller events. When this occurs on the smaller MHWs they may be broken up enough to no longer be counted, and therefore the overall count of events decrease. The decrease in the durations of the largest MHWs are greater than the decrease for the collective MHWs, but the spatial homogeneity of this pattern is more broken up (Figure 4B and 4E). The regions that show increasing durations in the largest MHW are spatially smaller than for the collective MHWs and the rates of increase are roughly one quarter of those seen in the collective MHWs (Figure 4B and 4E). Finally, the increasing and decreasing maximum intensities were similar in scale, but differed somewhat in their spatial patterns. Whereas the collective MHWs show clear warming trends in the northeast and south Pacific (Figure 4C), these features are much reduced for the largest MHWs (Figure 4F). The strong cooling signal in the collective MHWs north of Europe is replaced by a spatially broad warming trend in the largest MHWs in the area. The minor warming trend in the collective MHWs around the Kuroshio current is replaced by a spatially larger and more intense warming trend in the largest MHWs.


## Missing data

The effects of increasing missing data on MHW detection were more linear than the effects of time series length, with the exception of MHW count (Figure 2). Up to 25% missing data, the count of MHWs in a times series increases by up to 10 or decreases by down to 11 (Figure 2B). Past this point the count of MHWs falls at a roughly linear rate until there are 3 -- 22 fewer MHWs when 50% data are missing. The effect of missing data on the sum of the MHW days was linear at a rate of roughly 2% fewer MHW days in a time series for every 1% of missing data (Figure 2E). The effect of missing data on the maximum intensities of the MHWs was also linear, but very noisy. The average maximum intensities of MHWs detected in time series missing 50% of their data could increase by 3%, or decrease by 34%. 

The effect of random missing data on the single largest MHW in each time series was dramatic. As missing data in a time series increased, it becomes increasingly likely that the largest MHW in a time series is broken into multiple smaller events. It is not uncommon for this to begin with as little as 1% missing data, and increases in severity up to 25 -- 30% (Figure 3B). From this point the number of separate events the MHW is broken into decreases as even the smaller events are missed due to the loss of data. The duration of the focus MHW was almost always negatively impacted by missing data (Figure 3E). The decrease in duration follows a linear trend of a reduction ranging from 1 -- 3% per 1% of missing data. At 30% missing data it became common that the largest MHW would be removed entirely from the time series.

The effect that missing data can have on a MHW depends largely on the shape of the MHW, which is the area above the threshold climatology and below the observed anomaly. The WA event has a very pronounced peak (Figure 1A), so when more data are missing we see how likely it becomes that this peak is not being recorded. The maximum intensity measured in the control time series is 6.5°C, but we see that because very few days of this MHW were so intense, increases in missing data become more likely to remove these large values and the maximum intensity of the WA event begins to decrease more rapidly than either the NWA or Med MHWs.

The global patterns in missing data are unremarkable and generally consistent across the oceans (Appendix 3A).


## Long-term trends

The effect of an added linear trend on MHW detection was the most linear of the three tests and resulted in the largest changes in the metrics. Very rarely, an added linear trend led to a reduction in the count of MHWs in a time series, but generally it caused a linear increase at roughly 8 additional MHWs detected for every 0.1°C/dec added (Figure 3C). The effect that these additional MHWs had on the count of MHW days was an increase, ranging from 18 -- 90% for every 0.1°C/dec added (Figure 2F). The effect of linear trends on the maximum intensity of MHWs, though generally linear, could be either positive or negative at a rate of -9 -- 7% per 0.1°C/dec added.

The largest MHW in each time series was never divided into multiple events due to an added linear trend, but at 0.19°C/dec some MHWs began disappearing (-1 for count; Figure 3C). This is caused by the threshold climatology raising up enough due to the added decadal trend that the temperature anomaly is now lower than the threshold. The duration of the MHWs were affected differently by the added linear trend. The Mediterranean MHW showed practically no increase in duration due to an added linear trend, the Western Australia MHW saw a large jump at 0.03°C/dec, and the Northwest Atlantic MHW had a dramatic jump at an added trend of 0.09°C/dec, followed by a few other increases at larger added trends (Figure 3F). Likewise, all of the other 100 locations included in Figure 3 tend to jump up or down in dramatic steps. The positive jumps in duration occur because the temperature anomalies are increasing in magnitude more rapidly than the threshold and in some instances neighbouring MHWs in a time series will be connected into one event. When the duration of the largest MHW decreases rapidly it is because the leading or trailing edge of the MHW has heat spikes, and as the threshold raises due to the added linear trend, the temperature anomaly between the spikes and the main body of the MHW become separated by more than 2 days of below threshold temperatures. The effect that the linear trend had on the maximum intensity of each event was a simple linear function of the decadal trend and where in the time series the event occurred (Figure 3I). As in Figure 3C, at an added trend of 0.19°C/dec we see that some of the focus MHWs sink below the raising threshold and the change in maximum intensity drops to a value of -100% (Figure 3I). 

The global patterns in added decadal trends generally show that MHW metrics increase (Appendix 3B).


# Best practices

## Talk about linearity of responses as seen in Fig 2 and 3

There is much in the detection of MHWs that cannot be predicted because these events are anomalous by nature. It is however possible to know what the range in confidence we may have in our results is. In Table 1 the increasing rates of uncertainty per step in our tests is shown. In Table 2 the rates of change for the focus MHW from each time series are shown. From this information it is possible to say that, if we have a 

```{r}
best_table_10_years <- readRDS("../data/best_table_10_years.Rda")

knitr::kable(best_table_10_years, caption = "The rate of change in uncertainty as time series become increasingly sub-optimal. The columns containing numerical data show the slope (R^2^) of uncertainy for each step in the range column.")
```

```{r}
best_table_focus <- readRDS("../data/best_table_focus.Rda")

knitr::kable(best_table_focus, caption = "The rate of change in uncertainty as time series become increasingly sub-optimal.")
```

## Explanations for why this is

## Spatial relationships

## Examples for how to correct this

<!-- RWS: https://github.com/Tirgit/missCompare -->

<!-- RWS: A section, with a table, that shows the best practices for dealing with sub-optimal data. -->
RWS: I'll insert a table in this section that shows the slopes in the rates of change for the results. I'll also include examples of how one may perform fixes on sub-optimal results using examples. This may require that I create an additional figure to help illustrate the process.

The _a priori_ fix proposed for shorter time series, that of creating a smoother seasonal signal, created results with more similar overall days of MHWs per year, but all of the focus results were less similar than without applying the fix (results not shown; RWS: Could include as an Appendix if desired). This happened because the over smoothing of the seasonal signal prevents the detection of the smaller MHWs in the time series while inflating the size of the larger MHWs. A larger issue caused by short time series is the amount that the centre of the climatology increases or decreases, more so than the increase in variability caused, which additional smoothing seeks to address. This is not something that can be controlled for _a-priori_ and is better controlled for in a _post-hoc_ manner along the same lines as the proposed fix for decadal trends (see below).

Linear interpolation was proposed as an _a priori_ fix to address the issue of missing data and was very effective. This fix could potentially allow for the use of time series missing up to 40% of their data (Figure 4), assuming that there is not so much missing data that the period of time during a MHW that one may be wanting to study/isolate is completely missing.

<!-- Figure 5 -->

RWS: I'll write here about consecutive missing days of data and how that interferes with linear interpolation. This is shown as Figure 5.

<!-- Figure 6 -->

Given the relationship between decadal trends and the focus outputs seen above, one may be able to apply a _post-hoc_ correction to one's results if the decadal trend in a given area is known. 

RWS: I still need to flesh out the corrections for decadal trends. I do not plan on creating a figure for this.

RWS: It must also be shown that if one knows where ones time series is, the global patterns may be used to know what the slope of the change in the results introduced by sub-optimal data are. This then allows one to account for sub-optimal data challenges with much more confidence.


# Discussion

An investigation into the effects that sub-optimal data have on MHWs revealed that there are no clear statistical thresholds at which the outputs of the MHW detection algorithm become different than results generated by optimal data. The ranges of the size of effects that sub-optimal data have on MHW results was able to be determined and it is up to the user to decide for themselves what an acceptable uncertainty may be. We discuss here what the ranges of these uncertainties may mean for MHW research.

The MHW results from time series with 10 years of data are not appreciably different from the MHWs detected with 30 years of data. The rates at which the count, duration and intensity of events change from year-to-year within a single time series may change wildly, but a global sampling showed that increasing range in the uncertainty in the results one may expect are roughly linear. The rates seen in Table 1 may therefore be applied _post_hoc_ to MHWs detected in shorter time series to make the results comparable to those from an optimal time series.

An unexpected result was that increasing the length of a time series longer than 30 years reduced the probability that the outputs would be comparable by as much as shortening the time series did. This means that the common (often unspoken) assumption that using 30 years of data is the same as using > 30 years of data is incorrect. In other words, a 30 year time series is often thought of as the minimum length needed to constrain the climatology but we have shown here that using a climatology period greater than 30 years may create outputs as different as using fewer than 30 years. This is due to the decadal and multi-decadal variability in an environmental time series. In time series with less interannual variability there will be no appreciable difference between results calculated with a 30 year base period versus the full 37 year base period. In a time series with large interannual variability, such as the Western Australia time series, a base period of 30 years is not yet enough to completely average out the variability. It is therefore important to stress the adherence to the WMO standards for climatology periods as closely as possible, should one want one's results to be comparable to other studies. Increased smoothing of the climatologies derived from shortened time series was not an effective fix, in fact it made the results worse and we strongly recommend that the default climatology creation methodology in @Hobday2016 be adhered to.

The MHW algorithm proved to be resilient to missing data as long as there are not gaps larger than five days. Time series missing as much as 30% of their data may be used if necessary as the effect this may have on the count of MHWs is comparable to using a 10 year time series. Over 30% missing data and the count of MHWs in a time series is affected too much for the results to be reliable. That being said, the effect that missing data has on the overall MHW days in a time series is very predictable and can be corrected for rather easily as seen in Table 1. We showed here that a simple correction for missing data in a time series is to linearly interpolate over the gaps. It is not however recommended to do this with more than 40% missing data as this begins to dramatically distort the MHW detection algorithms ability to compute metrics for individual MHWs. If this is necessary to do for some reason, the resultant MHWs for the entire time series may still be used to infer the chronic and acute stress that organisms may face in a given location, but any individual events detected should not be taken as an accurate recording.

The decadal trends in times series have the largest potential effect on the MHWs detected. These effects are however the most predictable of the three tests and when taken with time series length and the year in which an event in question has occurred it is possible to infer a correction for the maximum intensity. The effect this has on the duration can also be worked out by considering the general rise (or fall) in the seasonal mean and threshold climatologies and how that may engulf neighbouring days or even other events. A concept to consider with the increase in duration from added decadal trends is that the temperatures in the time series increase "faster" than the 90th percentile threshold. So as the decadal trend increases, a given MHW effectively spreads outwards. If the rate of onset/decline for the MHW was more gradual (e.g. the NWA event) it will increase in duration more rapidly. If the rate of onset/decline was more rapid (e.g. the Med event), then the duration of the MHW won't change much with a larger decadal trend. If MHWs have close neighbouring MHWs then as they spread outward they may encounter each other and merge into a single event. This reduces the overall count of the MHWs detected in a time series while increasing the mean duration of the events detected.

RWS: An issue that needs to be discussed (according to a reviewer) is how increased heat content of sub-surface waters makes MHWs below the surface appear to last longer or be larger etc.

<!-- RWS: Perhaps a paragraph that talks about why using p-values for determining an acceptable threshold may be bad/problematic. I've not written this as it turned out that p-values were a complete dead end and aren't used anywhere in the results or discussion.  -->


# Conclusions

The acceptable sub-optimal data limits, the amount of uncertainty they introduce into the results, and their proposed corrections are as follows:  
  
1) Time series length:
  - A length of 10 years produces acceptable MHW metrics that may be used with some caution   
  - The uncertainty introduced into results by time series length is roughly +-xxx/year
  - Smoothing the climatology before detecting MHWs makes the results **worse**, not better, and should not be done  
2) Missing data:
  - The effect of missing data up to 30% on MHW results was comparable to the effect of a 10 year time series
  - The detected metrics for single large MHWs are no longer reliable with more than 20% missing data
  - Linear interpolation is an excellent fix for missing data up to 40%, assuming one does not have periods of consecutive missing data in excess of five days  
3) Long-term trends
  - Long-term trends had a greater effect on MHWs than the other two sub-optimal tests, but can be corrected for with the most confidence
  - If one knows the decadal trend present in a study area it is possible to correct for the max intensity of a MHW by subtracting the year of occurrence as a function of the slope present in the data 
  - For example, if the decadal trend in an area is 0.30°C/dec, and the peak date of an event is in the 25th year of a 30 year time series (83% of the length) then the the impact of the decadal trend on the max intensity will be roughly: 0.3*0.83 = 0.25(°C)

We have shown here that researchers must not shy away from the use of sub-optimal time series when the situation calls for it, such as coastal research or sub-surface analyses. Time series length may have an unpredictable effect on MHW results, but this may be corrected for within reason, and we have shown that time series lengths as short as 10 years are still useful for MHW research. Any shorter than 10 years however and the relationship between time series length and the effect on MHW metrics becomes too unpredictable to provide any corrections with confidence. Missing data has a larger effect on MHW detection, but is less of a concern as linear interpolation can largely fix the challenges this creates, up to a threshold of 40% missing data. Lastly, the effect of long-term trends on MHW detection are the most predictable and when taken with time series length may be corrected for with a reasonable degree of certainty. The MHW detection algorithm is very robust and we have shown here that one may be confident in the inter-comparability of one's results when using time series within a generous range of sub-optimal data challenges.


# Conflict of Interest

The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.


# Author Contributions

The majority of the text and figures were produced by RWS. A large portion of an early version of the text and a number of initial figures were produced by AJS. AJH, ECJO, and AJS provided several rounds of comments on the manuscript as it was developed. RWS synthesised the comments and uploaded the manuscript.


# Funding

This research was supported by National Sciences and Engineering Research Council of Canada Discovery Grant RGPIN-2018-05255.


# Acknowledgements

The authors currently have no acknowledgements to make.


# Data Availability Statement

The code and datasets generated for this study may be found at https://github.com/robwschlegel/MHWdetection.


# Figure legends

Figure 1: The focus marine heatwaves (MHWs) shown in red for the three reference time series A) Western Australia (WA), B) Northwest Atlantic (NWA), and C) Mediterranean (Med). Other MHWs shown in salmon. Each panel is centred around the peak date of the focus MHW, which is highlighted by a dark green vertical segment. The beginning and end of each event are demarcated with light green vertical segments. The seasonal mean climatology for each time series is shown as a light blue line, while the threshold climatology is shown with a dark blue line. The observed temperatures are shown as a black line.

Figure 2: The effect of sub-optimal data on the MHWs detected in the final 10 years of time series. The columns show the results for each of the three sub-optimal tests: time series length (10 -- 37 years), missing data (0 -- 50%), and added decadal trends (0.00 -- 0.30°C/dec). The rows show the three focus results from the MHW detection output: the change in the count of MHWs, the percentage of change in the sum of the MHW days, and the percentage change in the mean of the maximum intensities of the MHWs. Any samples that are significantly different (_p_-value <= 0.05) from the control are highlighted with red squares (there are none). The faint black lines in each panel show how the variable written on the y-axis changes as the data become more sub-optimal as shown on the x-axis as the sub-optimal tests were performed on 100 randomly selected pixels from the OISST dataset. The coloured lines show the effect of the sub-optimal tests on the three reference time series seen in Figure 1. The black vertical capped bars show the 5th and 95th quantiles of the values at each step along the x-axis.

Figure 3: This figure shows results from the same set of tests visualised in Figure 2, but focusses only on the effects the sub-optimal tests had on the single largest event in the final 10 years of data in each time series. Significant differences (_p_-value <= 0.05) are highlighted in red (there are none). The top row of panels, "Count (n)", shows the difference in the count of MHWs during what should be the duration of the focus event. A value of -1 means that no events were detected, and a value of 0 means that no additional MHWs were detected in addition to the single largest event. Theoretically this value should remain at 0, when it increases that means that the focus event is being chopped up into multiple smaller events. The bottom two rows of panels show percentage changes in the days of the focus MHW and its maximum intensity. A value 0f -100% means that no MHW was detected. 

Figure 4: Global map showing changes in MHW detection as the time series at each pixel is shortened from 30 to 10 years. The left column shows the effect of time series length on all MHWs detected in the final 10 years of data, while the right column shows the effect on only the largest MHW. Panels A & D show the change in count of MHWs as the time series are shortened, panels B & E show the change in the duration (days) of the detected MHW(s), and panels C & F show the change in the maximum intensities (°C). The labels on the colour bars at the bottom of each panel show what the values are at the 5th, 10th, 50th, 90th, and 95th quantiles of the data shown in the coloured pixels. Any values smaller/larger than the 5th/95th quantile were rounded to prevent the very long tails from interfering with the visualisation of the results.

Figure 5: The effect of linear interpolation on the MHW results. These panels show the same information as Figure 2BEH after the missing data were filled via linear interpolation and the MHW detection algorithm was re-run. RWS: I'll fix the text labels on this figure and add the effect on the focus events, too.

Figure 6: The count of consecutive missing days of data. RWS: I still need to create this figure.

Appendix 1: The effect of different 30 year climatology base periods on MHW results. RWS: I haven't created this yet as I'm not certain it is necessary.

Appendix 2: The effect of the sub-optimal tests on the seasonal mean and threshold climatologies. These panels show the same information as Figure 3 except that the variables shown are the thresholds from the MHW detection output.

Appendix 3A: The same global map as Figure 4, but with rates of change shown due to increasing missing data from 0 -- 50%.

Appendix 3B: The same global map as Figure 4, but with rates of change shown due to increasing decadal trends from 0.00 -- 0.30°C/dec.

Appendix 4: The effect of changing window widths on MHW output as a fix for time series length. RWS: I have these results but haven't made this figure yet as I don't think it is necessary.

# References
