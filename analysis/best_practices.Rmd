---
title: "Best practices"
author: "Robert Schlegel"
date: "`r Sys.Date()`"
description: "This vignette goes over the outcomes of the other vignettes to itemise best practices."
output: html_document
bibliography: bibliography.bib
---

```{r global_options, include = FALSE}
knitr::opts_chunk$set(fig.width = 6, fig.align = 'center',
                      warning = FALSE, message = FALSE, 
                      tidy = FALSE)
```

## Overview

In this vignette the results from the main three vignettes will be combined in order to visualise them simultaneously. Following this will be individual sections on how to address the challenges presented by length, missing data, and decadal trends respectively.


## Reference time series

```{r}
# Why are the buil-in time series so anomalous? ---------------------------

# We'll use the WA time series and the pixel just adjacent to it
# sst_WA_flat <- detrend(sst_WA) %>%
#   mutate(site = "WA") %>%
#   select(site, t, temp)

# which(c(seq(0.125, 179.875, by = 0.25), seq(-179.875, -0.125, by = 0.25)) == 112.375)
# sst_flat <- load_noice_OISST(OISST_files[450]) %>%
#   filter(lat > -30, lat < -20) %>%
#   unite(lon, lat, col = "site") %>%
#   group_by(site) %>%
#   group_modify(~detrend(.x)) %>%
#   data.frame()

# sst_ALL <- rbind(sst_flat, sst_WA_flat)
# unique(sst_ALL$site)

# Plot all time series together
# sst_ALL %>%
#   filter(t >= "2010-01-01", t <= "2012-12-31") %>%
#   ggplot(aes(x = t, y = temp)) +
#   geom_line(aes(group = site, colour = site)) +
#   scale_colour_viridis_d()

# Run full analyses on both
# result_ALL <- plyr::ddply(sst_ALL, c("site"), single_analysis, full_seq = T, .parallel = T)

# fig_box_plot(result_ALL, tests = "base", result_choice = "10_years")
# fig_box_plot(result_ALL, tests = "base", result_choice = "focus")

# These boxplots don't show us much, taking a different approach
# result_ALL %>%
#   filter(test == "trend", var == "duration", id == "sum_perc") %>%
#   ggplot(aes(x = index_vals, y = val)) +
#   geom_line(aes(group = site, colour = site)) +
#   scale_colour_viridis_d()
# In the figure above we may see that the closer we appraoch the centre of the WA MHW the less of an effect the
# increasing decadal trend is having on the overall number of MHWs detected
# We may deduce that this is because the WA MHW was so intense that it artificially raising up the 90th percentile
# so high that even with added decadal warming it is not enough to increase the other MHWs

# Now we want to look at how the count of overall events are affected
# result_ALL %>%
#   filter(test == "trend", var == "count", id == "n_perc") %>%
#   ggplot(aes(x = index_vals, y = val)) +
#   geom_line(aes(group = site, colour = site)) +
#   scale_colour_viridis_d()

# And there you have it, the built-in time series are just super wacky, their is nothing incorrect with the results

```


## Window widths

```{r}
# Why do some MHWs dissapear from wider windows? --------------------------

# -112.125 -28.875 # A pixel negatively affected by window widening
# which(c(seq(0.125, 179.875, by = 0.25), seq(-179.875, -0.125, by = 0.25)) == -112.125)
# sst <- load_noice_OISST(OISST_files[992]) %>%
#   filter(lat == -28.875)

# Detrend the selected ts
# sst_flat <- detrend(sst)

# Calculate MHWs from detrended ts
# sst_flat_MHW <- detect_event(ts2clm(sst_flat, climatologyPeriod = c("1982-01-01", "2018-12-31")))

# Pull out the largest event in the ts
# focus_event <- sst_flat_MHW$event %>%
#   filter(date_start >= "2009-01-01") %>%
#   filter(intensity_cumulative == max(intensity_cumulative)) %>%
#   select(event_no, date_start:date_end, duration, intensity_cumulative, intensity_max) %>%
#   mutate(intensity_cumulative = round(intensity_cumulative, 2),
#          intensity_max = round(intensity_max, 2))

# Quickly visualise the largest heatwave in the last 10 years of data
# heatwaveR::event_line(sst_flat_MHW, start_date = "2009-01-01", metric = "intensity_cumulative")

# Normal window width
# window_5_MHW <- detect_event(ts2clm(sst_flat, climatologyPeriod = c("1982-01-01", "2018-12-31")))
# heatwaveR::event_line(window_5_MHW, start_date = "2009-01-01", metric = "intensity_cumulative")

# 10 day window
  # Already here we see why the event falls away
  # The focus MHW was just staying above the down slope of the seasonal dive into winter
  # When the window half width is expanded the seasonal decline becomes less steep and the
  # observed temperature is no longer above the 90th percentile
# window_10_MHW <- detect_event(ts2clm(sst_flat, climatologyPeriod = c("1982-01-01", "2018-12-31"), windowHalfWidth = 10))
# heatwaveR::event_line(window_10_MHW, start_date = "2009-01-01", metric = "intensity_cumulative")

# 20 day window
# window_20_MHW <- detect_event(ts2clm(sst_flat, climatologyPeriod = c("1982-01-01", "2018-12-31"), windowHalfWidth = 20))
# heatwaveR::event_line(window_20_MHW, start_date = "2009-01-01", metric = "intensity_cumulative")

# 30 day window
# window_30_MHW <- detect_event(ts2clm(sst_flat, climatologyPeriod = c("1982-01-01", "2018-12-31"), windowHalfWidth = 30))
# heatwaveR::event_line(window_30_MHW, start_date = "2009-01-01", metric = "intensity_cumulative")

# Now let's have a peak at each step along the way, just for laughs
# ts2clm_window <- function(window_choice, df = sst_flat){
#   res <- ts2clm(df, climatologyPeriod = c("1982-01-01", "2018-12-31"), windowHalfWidth = window_choice) %>%
#     mutate(site_label = paste0("window_",window_choice))
#   return(res)
# }

# Calculate clims
# sst_clim <- plyr::ldply(seq(5, 30, by = 5), ts2clm_window, .parallel = T)

# Climatologies doy
# sst_clim_only <- sst_clim %>%
#   select(-t, -temp) %>%
#   unique()

# Calculate events
# sst_event <- sst_clim %>%
#   group_by(site_label) %>%
#   group_modify(~detect_event(.x)$event)

# Find largest event in most recent ten years of data
# focus_event <- sst_event %>%
#   filter(date_start >= "2009-01-01") %>%
#   group_by(site_label) %>%
#   filter(intensity_cumulative == max(intensity_cumulative)) %>%
#   ungroup()

# Merge with results for better plotting
# sst_focus <- left_join(sst_clim,
#                        focus_event[,c("site_label", "date_start", "date_peak", "date_end")], by = "site_label") %>%
#   mutate(site_label = factor(site_label, levels = c("window_5", "window_10", "window_15",
#                                                     "window_20", "window_25", "window_30")))

# trend_fig <- fig_1_plot(sst_focus, spread = 150)
# trend_fig

# Look at differences between the seas/thresh for each window
# sst_clim_only %>%
#   select(-doy) %>%
#   gather(key = "var", value = "val", seas, thresh) %>%
#   group_by(site_label, var) %>%
#   summarise_if(.predicate = is.numeric, .funs = c("min", "median", "mean", "max")) %>%
#   ungroup() %>%
#   gather(key = "stat", value = "val", -site_label, - var) %>%
#   mutate(site_label = factor(site_label, levels = c("window_5", "window_10", "window_15",
#                                                     "window_20", "window_25", "window_30"))) %>%
#   arrange(site_label) %>%
#   ggplot(aes(x = stat, y = val, colour = site_label)) +
#   geom_point() +
#   scale_colour_brewer() +
#   facet_wrap(~var)

# Now let's look at all of the 100 random results to see how this shakes out
# random_results <- readRDS("data/random_results_100.Rda")
# unique(random_results$test)
# all_clims <- random_results %>%
#   filter(test %in% c("length", "window_10", "window_20", "window_30"),
#          index_vals == 30,
#          var %in% c("seas", "thresh"),
#          id %in% c("min", "median", "mean", "max", "sd")) %>%
#   ggplot(aes(x = id, y = val, fill = test)) +
#   geom_boxplot() +
#   scale_fill_brewer(palette = "YlOrRd") +
#   facet_wrap(~var)
# all_clims
```

## Linearity of fits

```{r}
# Run the linear models at each possible step to deduce where any inflections points may be
# This is determined by tracking the change in R2 values, with lower values being bad
quant_missing <- plyr::ldply(3:50, trend_test, .parallel = T, test_sub = "missing", start_val = 0)
quant_missing_A <- plyr::ldply(3:25, trend_test, .parallel = T, test_sub = "missing", start_val = 0)
quant_missing_B <- plyr::ldply(3:24, trend_test, .parallel = T, test_sub = "missing", start_val = 0.26)
quant_interp <- plyr::ldply(3:50, trend_test, .parallel = T, test_sub = "interp", start_val = 0)
quant_trend <- plyr::ldply(3:30, trend_test, .parallel = T, test_sub = "trend", start_val = 0)
quant_length_A <- plyr::ldply(3:20, trend_test, .parallel = T, test_sub = "length")
quant_length_B <- plyr::ldply(3:7, trend_test, .parallel = T, test_sub = "length", rev_trend = T)
quant_ALL <- rbind(quant_missing_A, quant_missing_B, quant_interp, quant_trend, quant_length_A, quant_length_B)

## Test visuals to determine that the trends above are lekker
# First create a line plot of the results
quant_ALL %>%
  filter(test == "missing") %>%
  ggplot(aes(x = end_val, y = r2)) +
  geom_point(aes(colour = var)) +
  geom_line(aes(colour = var)) +
  facet_grid(stat~test, scales = "free_x")

# Filter out the trends that cover the correct ranges
trend_filter <- data.frame(test = c("length", "length", "missing", "missing", "interp", "trend"),
                           start_val = c(30, 30, 0, 0.26, 0, 0),
                           end_val = c(10, 37, 0.25, 0.5, 0.5, 0.3))
quant_filter <- quant_ALL %>%
  right_join(trend_filter, by = c("test", "start_val", "end_val")) %>%
  mutate(slope = ifelse(test == "length" & end_val == 10, -slope, slope),
         end_point = end_val*slope) %>%
  filter(stat != "iqr50", stat != "iqr90")

# Then project them onto the real data
ggplot(random_quant) +
  # 90 CI crossbars
  # Need different lines for tests due to the different x-axis interval sizes
  geom_crossbar(data = filter(random_quant, test == "length"),
                aes(x = index_vals, y = 0, ymin = q05, ymax = q95),
                fatten = 0, fill = "grey70", colour = NA, width = 1) +
  geom_crossbar(data = filter(random_quant, test != "length"),
                aes(x = index_vals, y = 0, ymin = q05, ymax = q95),
                fatten = 0, fill = "grey70", colour = NA, width = 0.01) +
  # IQR Crossbars
  geom_crossbar(data = filter(random_quant, test == "length"),
                aes(x = index_vals, y = 0, ymin = q25, ymax = q75),
                fatten = 0, fill = "grey50", width = 1) +
  geom_crossbar(data = filter(random_quant, test != "length"),
                aes(x = index_vals, y = 0, ymin = q25, ymax = q75),
                fatten = 0, fill = "grey50", width = 0.01) +
  # Median segments
  geom_crossbar(data = filter(random_quant, test == "length"),
                aes(x = index_vals, y = 0, ymin = q50, ymax = q50),
                fatten = 0, fill = NA, colour = "black", width = 1) +
  geom_crossbar(data = filter(random_quant, test != "length"),
                aes(x = index_vals, y = 0, ymin = q50, ymax = q50),
                fatten = 0, fill = NA, colour = "black", width = 0.01) +
  geom_hline(aes(yintercept = 0), colour = "black", linetype = "dashed") +
  geom_segment(data = quant_filter, aes(x = start_val, y = intercept, xend = end_val, yend = end_point, colour = stat)) +
  scale_colour_brewer(palette = "Dark2") +
  scale_x_continuous(expand = c(0, 0)) +
  facet_grid(var ~ test, scales = "free", switch = "both") +
  theme(legend.position = "top")
```


<!-- ## Reference time series -->

<!-- ```{r ref-ts-overview} -->
<!-- # A multi-panel summary figure with images and tables -->
<!-- load("data/sst_ALL.Rdata") -->

<!-- # sst_ALL_summary <- sst_ALL %>%  -->

<!-- # Poential panels -->
<!-- # 1) The base time series -->
<!-- #   1.1) Rug pplot showing events -->
<!-- #   1.2) Events filled in with flames -->
<!-- #   1.3) Overlay thresholds -->
<!-- #   1.4) Overlay category thresholds -->
<!-- # 2) Mini map showing pixel location -->
<!-- # 3) Stats table (showing relevant stats for/from best practices) -->
<!-- # 4) The climatolgies/categories as there own doy x-axis panel -->
<!-- # 5) Lolli plot showing events -->

<!-- # ggplot(sst_ALL_summary) -->

<!-- ``` -->


<!-- ## Overview of results -->

<!-- The following figures show the combined results from time series length, missing data, and decadal trends side by side for each of the three components of the results. This helps to create a more complete pictures of the importance of the different variables. -->


<!-- ### Climatologies -->


<!-- ### Event metrics -->


<!-- ### Category counts -->




